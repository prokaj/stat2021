%\def\option{}
\providecommand{\option}{handout}
\documentclass[aspectratio=169,notheorems,9pt,\option]{beamer}

\input{preambulum.tex}

\begin{document}

\maketitle

\begin{frame}{Rásonyi Miklós habilitációs előadása}
\vfill
  \begin{center}
    \textbf{Centrális határeloszlás tétel}
    
    \vspace{1cm}

    2021. április 16. (péntek), 10 óra 30 perc
\end{center}
\vfill

\url{https://zoom.us/j/99761822815?pwd=dTdKM3l5M1NpTER6T0JLbW5MNVhiZz09}{}\\
%\begin{verbatim}
Meeting ID: 997 6182 2815\\
Passcode: 286612
%\end{verbatim}
\end{frame} 

\begin{frame}{Hipotézis vizsgálati feladatok, példák}
  \begin{itemize}
    \item A kérdés nem az ismeretlen paraméter értéke hanem az, hogy egy állítás (hipotézis) teljesül-e rá.
    \item Egy gyártósor működése elfogadható, ha a selejt arány $5\%$ alatt van. Ha a gépet beállítják, 
    akkor ez az arány $1\%$, de a használat során a gépsor elállítódik és a selejt arány idővel nő.
    \item Minden nap végén mintát veszünk a termékekből, ez alapján szeretnénk dönteni arról, 
    hogy időszerű-e a gépsor beállítása. 
    \item Itt a hipotézis (nullhipotézis) az, hogy selejt arány az elfogadható szint alatt van.
    \item Egy döntési szabály (statisztikai próba) lehet az, hogy ha a mintában a selejt arány egy \textit{kritikus értéket} 
    meghalad, akkor a gép beállítása mellett döntünk, ellenkező esetben folyhat tovább a termelés.
    \item Mekkora legyen a kritikus érték?
    
    Ha a kritikus érték túl nagy, akkor a selejt arány elfogadhatatlanul magas lesz, ha túl kicsi akkor 
    feleslegesen áll a termelés a gép beállítása alatt.
  \end{itemize}  
\end{frame}


\begin{frame}{Hipotézis vizsgálati feladat, fogalmak}
    \begin{itemize}
    \item \textbf{Statisztikai hipotézis}. A minta eloszlásának valamely
      jellemzőjére vonatkozó kijelentés.
      
      $(\Omega,\cA,\cP)$ statisztikai mező. $\cP=\cP_0\cup\cP_1$,
      ($\cP_0\cap\cP_1=\emptyset$).
      
      $H_0$ \textbf{nullhipotézis}: a valódi eloszlás $\in\cP_0$,
      
      $H_1$ \textbf{ellenhipotézis}: a valódi eloszlás $\in\cP_1$.
    
   
    \item Ha $\cP=\set{\P[\theta]}{\theta\in\Theta}$ paraméteres család,
      akkor $\cP=\cP_0\cup^*\cP_1$ megfelel egy
      $\Theta=\Theta_0\cup^*\Theta_1$ felbontásnak. 
      $H_0:\,\theta\in\Theta_0$, $H_1:\,\theta\in\Theta_1$.
    
    \item A bevezető példában indikátor mintánk volt $\Omega=\mfX=\smallset{0,1}^n$. 
      $\theta\in\Theta=(0,1)$ az ismeretlen selejt arány. 
      
      $H_0: \theta\leq 0.05$, $H_1: \theta>0.05$, $\Theta_0=(0,0.05]$ és $\Theta_1=(0,05,1)$.
    \item A $H_0$, ill. $H_1$ hipotézis egyszerű, ha $\cP_0$, ill.
      $\cP_1$ egy elemű.
    \item Egy hipotézis összetett, ha nem egyszerű, azaz a $\cP_0$
      vagy $\cP_1$ több elemű.
    \item \textbf{Statisztikai próba}. Döntés a minta alapján
      $H_0$-ról. Azaz $\mfX=\mfX_0\cup^*\mfX_1$. Ha
      a megfigyelés $X\in\mfX_0$, akkor elfogadjuk a nullhipotézist, ellenkező
      esetben elutasítjuk.
  
      $\mfX_0$ neve \textbf{elfogadási tartomány}
  
      $\mfX_1$ neve elutasítási, vagy \textbf{kritikus tartomány}
    \item A bevezető példában ha $c$ a kritikus érték, akkor $\mfX_1=\set{x\in\mfX}{\bar{x}>c}$.
    \end{itemize}
    
  \end{frame}
  
  
  \begin{frame}{Hiba lehetőségek}
   
    \begin{itemize}
    \item 
    
    \textbf{Elsőfajú hiba}. A nullhipotézis igaz, de elvetjük
      (téves elutasítás)
    
      \textbf{Másodfajú hiba}. A nullhipotézis nem igaz, de mégis elfogadjuk
      (téves elfogadás)
    
    \item A bevezető példában: 
    
    $H_0: \theta\leq0.05$, azaz elsőfajú hibát követünk el, ha a gép beállítása még nem időszerű
    de a mintában a selejt arány a kritikus érték felett van.

    $H_1: \theta>0.05$, azaz másodfajú hibát követünk el, ha a selejt arány a mintában kicsi, pedig a gép beállítása időszerű.

    \item \textbf{Fix mintaelemszám esetén az egyik fajta hiba valószínűségét
      csak a másik növelése árán lehet csökkenteni.}
      
    \item Feladat. Az elsőfajú hiba valószínűsége legyen kicsi (tipikusan
      nem nagyobb, mint 5\%) és ezen feltétel mellett a másodfajú hiba valószínűsége
      legyen minél kisebb.

    \item Jelentés: A nullhipotézist, ha lehet elfogadjuk. Csak akkor
      utasítjuk el, ha az adatok ennek ,,ellentmondanak''.
  
      $H_0$ elfogadása csak annyit jelent, hogy az adatok alapján lehetséges
      hogy  $H_0$ igaz.
  
      $H_0$ elutasítása az \textbf{informatív döntés}, ez ugyanis annyit jelent,
      hogy a megfigyelések $H_0$ ellen szólnak. %, az valószínűleg nem igaz.
    \end{itemize}
  
    \continue
    Példák.
    \begin{itemize}
    \item Gyógyszerkutatásban: $H_0:$ az új hatóanyag hatástalan, $H_1:$
      az új hatóanyag hatásos. 
    \item Növénynemesítés. $H_0:$ az új változat termésátlaga nem nagyobb
      mint a most használt fajtáké. $H_1:$ az új változat termésátlaga nagyobb.
    \end{itemize}
    
  \end{frame}
  
  \begin{frame}{Véletlenített próba, próbafüggvény, terjedelem, szint, erő}
    \begin{itemize}
    \item Egy statisztikai próba leírható az elutasítási tartomány
      $\mfX_1$ indikátorával. $\phi (x)=\I{x\in \mfX_1}$.
  
      Ekkor $\phi (x)$ az elutasítás valószínűsége, ha a megfigyelés
      $x$. $\phi$ neve \textbf{próbafüggvény} vagy \textbf{döntési függvény}.
      
    \item Véletlenített próba. $\phi:\mfX\to[0,1]$.
  
      Ha $\phi:\mfX\to\smallset{0,1}$, akkor a próba nem véletlenített.
      
    \item A $\phi$ próba \textbf{terjedelme} az elsőfajú hiba elkövetésének
      maximális valószínűsége
      \begin{displaymath}
        \alpha (\phi) =\sup_{\theta\in\Theta_0}\E[\theta]{\phi}
      \end{displaymath}
    \item A $\phi$ próba \textbf{ereje} annak a valószínűsége, hogy $H_0$ nem
      teljesül és ezt felismerjük. Ez egy $\Theta_1$-n értelmezett
      $\psi$ függvény, az \textbf{erőfüggvény}
      \begin{displaymath}
        \psi (\theta)=\psi (\theta,\phi)=\E[\theta]{\phi}, \quad \theta\in\Theta_1
      \end{displaymath}
    \item Az azonos terjedelmű próbákat az erőfüggvény alapján hasonlíthatjuk össze. 
    \end{itemize}
    \continue
    Megjegyzés. Gyakran a legfeljebb $\alpha$ terjedelmű próbát is
    $\alpha$ terjedelműnek mondják.
  
    Ha a próba terjedelme $\alpha$, akkor a szintje $1-\alpha$.
  \end{frame}
  
  \begin{frame}{Statisztikai próbák jellemzői}
  
    $\phi:\mfX\to[0,1]$ próba függvény. $\phi (x)$ a
    $H_0$ %nullhipotézis
    elutasításának valószínűsége, ha a megfigyelés $x$. 
    \begin{itemize}
    \item $\phi$ \textbf{torzítatlan}, ha ereje nem kisebb a
      terjedelménél:
      \begin{displaymath}
        \sup_{\theta\in\Theta_0} \E[\theta] {\phi (X)}\leq \inf_{\theta\in\Theta_1}\E[\theta]{\phi (X)}
      \end{displaymath}
    \item $\phi$ \textbf{egyenletesen legerősebb} próba (e.l.p.), ha
      ereje legalább akkora, mint tetszőleges vele azonos terjedelmű
      próba ereje.
      \begin{displaymath}
        \psi (\theta,\phi)=\E[\theta]{\phi}=\sup\set{\psi
          (\theta,\phi')}{\alpha (\phi')=\alpha (\phi)} \quad\forall\theta\in\Theta_1
      \end{displaymath}
      $\alpha (\phi)=\sup_{\theta\in\Theta_0}\E[\theta]{\phi}$.
  
      Egyenletesen legerősebb próba nem feltétlenül létezik.
  
      Ha $\phi$ egyenletesen legerősebb, akkor torzítatlan is, mert ereje
      legalább akkora, mint a %az $\alpha (\phi)$ terjedelmű
      $\phi'(x)=\alpha (\phi)$ próba ereje.
    \item $\phi$ \textbf{legszigorúbb}, ''ha legjobban közelíti az
      erőfüggvény burkolóját'', azaz $\phi$ minimalizálja
      \begin{displaymath}
        \sup_{\theta\in\Theta_1}(\bpsi (\theta,\alpha)-\psi(\theta,\phi))
        \quad\text{értékét, ahol}\quad
        \bpsi (\theta,\alpha)=\sup\set{\psi (\theta,\phi)}{\alpha
          (\phi)=\alpha},\quad\theta\in\Theta_1
        % \quad
        %\text{\phi minimalizálja}&\quad
        %=\inf\set{\psi (\theta,\alpha)-\psi
        %(\theta,\phi_1)}{\alpha (\phi_1)=\alpha (\phi)}
      \end{displaymath}
      
    \item  $\phi_n$ $n$-elemű mintára épülő $\alpha$ terjedelmű próba.
      $(\phi_n)$ \textbf{konzisztens}, ha $\psi (\theta,\phi_n)\to1$
      %minden
      $\forall\theta\in\Theta_1$-re.
    \end{itemize}
  \end{frame}
  
  
  \begin{frame}{Próbák konstruálása}
    \begin{itemize}
    \item Látni fogjuk, hogy a legtöbb próba $\phi (x)=\I{T (x)>c}$
      alakú. 
    \item $T$ olyan statisztika, ami $\theta\in\Theta_1$ mellett
      tipikusan nagy értékekre vezet, míg $\theta\in\Theta_0$ esetén
      nem.
    \item $T$ neve \textbf{próba statisztika}, $c$ neve \textbf{kritikus
        érték}
    \item Ha $S$ elégséges statisztika, akkor $\phi'
      =\E[\theta]{\phi|S}$ nem függ $\theta$-tól, terjedelme, ereje
      azonos $\phi$-vel. Azaz $\phi$-t elég az elégséges statisztika
      függvényei között keresni.
    \item Ha determinisztikus próbával a megengedett $\alpha$
      terjedelem nem érhető el, akkor véletlenítéssel lehet javítani a
      próbán.
  
      Azaz
      \begin{displaymath}
        \alpha'=\sup_{\theta\in\Theta0}\P[\theta]{T>c}<\alpha\quad
        \sup_{\theta\in\Theta0}\P[\theta]{T\geq c}\geq\alpha
      \end{displaymath}
      akkor
      \begin{displaymath}
        \phi (x)=
        \begin{cases}
          1 &T (x)>c\\
          p &T (x)=c\\
          0 &T (x)<c
        \end{cases}
      \end{displaymath}
      $p\sup_{\theta\in\Theta_0}\P[\theta]{T=c}=\alpha-\alpha'$.
    \end{itemize}    
  \end{frame}
  
  \begin{frame}{Neyman--Pearson lemma I.}
    
    \begin{lemma}
      Egyszerű hipotézis vizsgálati feladatban a likelihood hányados próba
      a legerősebb a vele azonos terjedelmű próbák között.
      
      Azaz, ha $c>0$, $g:\mfX\to [0,1]$, és
      \begin{displaymath}
        \phi (x)=
        \begin{cases}
          1 & f_1 (x)> cf_0 (x)\\
          g(x) & f_1 (x)=cf_0 (x)\\
          0 & f_1 (x)<cf_0 (x)
        \end{cases}
      \end{displaymath}
      akkor tetszőleges $\phi'$ próbafüggvényre
      \begin{displaymath}
        \E[0]{\phi'}\leq \E[0]{\phi}\quad\implies\quad
        \E[1]{\phi'}\leq \E[1]{\phi}
      \end{displaymath}
    \end{lemma}
    \continue
    \begin{displaymath}
      \E[1]{\phi-\phi'}=\int_{\mfX}
      (\phi-\phi')f_1d\lambda\geq
      \int_{\mfX}
      (\phi-\phi')cf_0d\lambda=c\E[0]{\phi-\phi'}\geq0
    \end{displaymath}
    Ugyanis $(\phi-\phi')(f_1-cf_0)\geq 0$. Ez eset szétválasztással látható.
  \end{frame}
  
  \begin{frame}{Neyman--Pearson lemma II.}
    
    \begin{lemma}[Egzisztencia]
      Egyszerű hipotézis vizsgálati feladatban tetszőleges $\alpha\in
      (0,1)$-re létezik $\alpha$ terjedelmű  likelihood hányados próba.
    \end{lemma}
    Megjegyzés. Ez a legerősebb a legfeljebb $\alpha$ terjedelmű próbák között.
    \continue
      
    $c>0$, $p\in [0,1]$, megválasztásával elérhető, hogy a
    \begin{displaymath}
        \phi (x)=
        \begin{cases} 
          1 & f_1 (x)> cf_0 (x)\\
          p & f_1 (x)=cf_0 (x)\\
          0 & f_1 (x)<cf_0 (x)
        \end{cases}
      \end{displaymath}
      próba terjedelme pontosan $\alpha$ legyen. 

      Ha $c=\inf\set{c>0}{\P[0]{f_1(X)>cf_0(X)}<\alpha}$, akkor 
      \begin{displaymath}
        \P[0]{f_1(X)\alert{>}cf_0(X)}\leq \alpha \leq \P[0]{f_1(X)\alert{\geq} cf_0(X)}. 
      \end{displaymath}
      és így létezik $p\in[0,1]$, hogy
      \begin{displaymath}
        \alpha = (1-p)\P[0]{f_1(X)\alert{>}cf_0(X)}+p\P[0]{f_1(X)\alert{\geq}cf_0(X)}=\E[0]{\phi}.
      \end{displaymath} 
      % $\P{\P[0]{f_1(X)\geq cf_0(X)}\geq\alpha$
      % \begin{displaymath}
      %   \E[0]{\phi}=\P[0]{f_1(X)>cf_0(X)}+p\P{f_1(X)=cf_0(X)}
      % \end{displaymath}
      % Itt $c=\inf\set{c}{\P[0]{f_1(X)>cf_0(X)}<\alpha}$. Ekkor $\P{\P[0]{f_1(X)\geq cf_0(X)}\geq\alpha$.

  \end{frame}
  
  
  \begin{frame}{Neyman--Pearson lemma III.}
    
    \begin{lemma}[Unicitás]
      Egyszerű hipotézis vizsgálati feladatban, ha  $\phi_1$ legerősebb
      próba a legfeljebb $\alpha$ terjedelmű próbák között, akkor $\phi_1$
      likelihood hányados próba és vagy $\alpha (\phi_1)=\alpha$ vagy $\psi (\phi_1)=1$.
    \end{lemma}
    \begin{itemize}
    \item Legyen $\phi$ a pontosan $\alpha$ terjedelmű (esetleg
      véletlenített) likelihood hányados próba ($c$ a kritikus
      értéke). Ekkor
      \begin{displaymath}
        0\geq \E[1]{\phi-\phi_1}-c\E[0]{\phi-\phi_1}=\int (f_1-cf_0)
        (\phi-\phi_1)d\lambda\geq 0
      \end{displaymath}
  
     
    \item Azaz $(f_1-cf_0) (\phi-\phi_1)=0$ $\lambda$ m.m., Vagyis $\phi_1$
      is likelihood hányados próba.
      
    \item Ha $\alpha (\phi_1)<\alpha$, és $\psi (\phi)<1$, akkor véletlenítéssel növelhető
      lenne az ereje. Mivel $\phi_1$ a legerősebb próba, ez nem
      lehetséges, tehát vagy $\alpha (\phi_1)=\alpha$ vagy $\psi (\phi_1)=1$. 
    \end{itemize}  
  \end{frame}

  \begin{frame}{Példa}
    \begin{itemize}
      \item $X_1,\dots,X_n$ indikátor minta. $H_0: \theta=\theta_0$, $H_1:\theta=\theta_1$, ahol $\theta_0<\theta_1$.
      \item Ekkor $f_i(x)=\theta_i^{\sum x_k}(1-\theta_i)^{\sum(1-x_k)}$ és
      \begin{displaymath}
        \frac{f_1(x)}{f_0(x)}=\zfrac*{1-\theta_0}{1-\theta_1}^n\cdot\zjel*{\frac{\theta_1}{1-\theta_1}:\frac{\theta_0}{1-\theta_0}}^{\sum x_i}.
      \end{displaymath}
      \item A likelihood hányados a $\sum X_i$ statisztika monoton növő függvénye, 
      azaz a likelihood hányados próba döntési függvénye:
      \begin{displaymath}
        \phi(x)=\I{\sum x_k>c}+p\I{\sum x_k=c},
      \end{displaymath}
      ahol $c$ és $p$ értékét a $\E[0]{\phi(X)}=\alpha$ összefüggés határozza meg.

      \item Vegyük észre, hogy  a döntési függvény nem függ $\theta_1$ konkrét értékétől, 
      csak a $\theta_1>\theta_0$ összefüggést használtuk. A kapott próba egyenletesen 
      legerősebb a $H_1: \theta>\theta_0$ ellenhipotézissel szemben is.
    \end{itemize}    
  \end{frame}

  \begin{frame}{Példa folytatása, aszimptotikus viselkedés}
    \begin{itemize}
      \item $X_1,\dots,X_n$ indikátor minta. $H_0: \theta=\theta_0$, $H_1:\theta=\theta_1$, ahol $\theta_0<\theta_1$.
      \item A likelihood hányados a $\sum X_i$ statisztika monoton növő függvénye, 
      azaz a likelihood hányados próba döntési függvénye:
      \begin{displaymath}
        \phi(x)=\I{\sum x_k>c}+p\I{\sum x_k=c},\quad
        \text{ahol $c$ és $p$ értékét a $\E[0]{\phi(X)}=\alpha$ összefüggés adja.}
      \end{displaymath}
      %ahol $c$ és $p$ értékét a $\E[0]{\phi(X)}=\alpha$ összefüggés határozza meg.
      \item Ha $n$ nagy, akkor $n^{-1/2}\sum_i (X_i-\theta_0)$ közelítőleg $N(0,\theta_0(1-\theta_0))$ eloszlású 
      és a kritikus érték ez alapján választható. $c_n=n\theta_0+\sqrt{n\theta_0(1-\theta_0)}\Phi^{-1}(1-\alpha)$,
      nagy $n$-re $p=0$ értékét vehetjük nullának.
      % \item A próba ereje:
      % \begin{displaymath}
      %   \psi(\theta_1)=
      %   \P[1]{\sum X_i>c_n}
      %   %=\P[1]{\frac{\sum(X_i-\theta_1)}{\sqrt{n(\theta_1(1-\theta_1))}}>\frac{c_n-n\theta_1}{\sqrt{n\theta_1(1-\theta_1)}}}
      %   %=\P{Z> -a\sqrt{n}+b}=\P{-Z<a\sqrt{n}-b},
      %   %\quad\text{ahol $Z\sim N(0,1)$}
      % \end{displaymath}
      %$a=-(\theta_0-\theta_1)>0$, $b=\sqrt{\frac{\theta_0(1-\theta_0)}{\theta_1(1-\theta_1)}}\Phi^{-1}(1-\alpha)>0$.
      \item Emlékeztető
      \begin{proposition}<.->[Hoeffding egyenlőtlenség]
        $Z_1,\dots,Z_n$ független változók, $0\leq Z_i\leq 1$, $\eps>0$. 
        Ekkor $\P{\sum Z_i> \sum \E{Z_i}+n\eps}\leq e^{-2n\eps^2}$
      \end{proposition}
      $(1-Z)$-re áttérve: $\P{\sum Z_i<\sum \E{Z_i}-n\eps}\leq e^{-2n\eps^2}$.
      \begin{displaymath}
        1-\psi(\theta_1)
        =\P[1]{\sum_{i=1}^n X_i<c_n}
        %=\P[1]{\sum_{i=1}^n (1-X_i)>n-c_n}
        \leq \exp{-2n\zfrac*{n\theta_1-c_n}{n}^2}
        \leq e^{-2n(\theta_1-\theta_0)^2+a\sqrt{n}+b}
      \end{displaymath}
      Azaz az erő geometriai sebességgel tart egyhez, 
      ha minta elemszám végtelenhez tart.
    \end{itemize} 
  \end{frame}
  
  \begin{frame}{Általánosítás: kritikus érték aszimptotikája}
    \begin{itemize}
    \item Egyszerű hipotézis vizsgálati feladat. $f_1,f_0$ egy mintaelem
      sűrűségfüggvénye. Tegyük fel, hogy $f_1,f_0>0$.
    \item %Jelölés
      \begin{displaymath}
        \xi_i=-\log  \frac{f_1(X_i)}{f_0 (X_i)},\quad\text{ekkor}\quad
        \E[0]{\xi_i}=\int -\log\frac{f_1}{f_0}f_0d\lambda= D(\P[0]\|\P[1]).
      \end{displaymath}
      Belátható, hogy ha $f_1\neq f_0$, akkor $0<\E[0]{\xi_i}$.
      Tegyük fel, hogy $\E[0]{\xi_i}<\infty$ és $\sigma^2=\D[0]^2{\xi}<\infty$.
    \item A likelihood hányados próba $\sum_i\xi_i$-vel is felírható.
      \begin{displaymath}
        T_n=\prod_{i=1}^n\frac{f_1 (X_i)}{f_0 (X_i)}>c_n\quad\iff\quad
        \sum\frac{\xi_i- D(\P[0]\|\P[1])}{\sqrt{n}\sigma}<t_n,\quad
        c_n=\exp{-n D(\P[0]\|\P[1])-\sqrt{n}\sigma t_n}.
      \end{displaymath}
    \item Terjedelem $\alpha$. A CHT alapján
      \begin{displaymath}
        \sum_{i=1}^n\frac{\xi_i-D(\P[0]\|\P[1])}{\sqrt{n}\sigma}\dto N (0,1)
        \quad\text{ha $H_0$ igaz, és}\quad 
        \P[0]{\sum_{i=1}^n\frac{\xi_i-D(\P[0]\|\P[1])}{\sqrt{n}\sigma}<t_n}\to\alpha.
        %\implies\quad
        %t_n\to\Phi^{-1} (\alpha)
      \end{displaymath}
      Belátjuk, hogy ebből $t_n\to \Phi^{-1}(\alpha)$ következik.
    \item Ha
      \begin{displaymath}
        \hat c_n=\exp{-n D(\P[0]\|\P[1])-\sqrt{n}\sigma \Phi^{-1}
          (\alpha)},\quad\hat\phi_n (x)=\I{T_n>\hat c_n},\quad
        \text{akkor}\quad\alpha (\hat\phi_n)\to\alpha
      \end{displaymath}      
    \end{itemize}
\end{frame}

\begin{frame}{Kullback-Leibler divergencia}
  \begin{df}
    $\P[0]$, $\P[1]$ valószínűségi mértékek az $(\Omega,\B)$ mérhető téren. 
    \begin{displaymath}
      D(\P[0]\|\P[1]) = \begin{cases}
        \E[0]{-\log\frac{d\P[1]}{d\P[0]}}& \text{ha $\P[1]\ll\P[0]$}\\
        \infty&\text{különben}
      \end{cases}
    \end{displaymath}
  \end{df}
  \begin{itemize}
    \item $D(\P[0]\|\P[1])=\int -\log\frac{f_1}{f_0} f_0$, ha $f_1,f_0$ a két sűrűségfüggvény.
    Ez a formula nem függ a domináló mérték választásától.
    \item $-\log$ konvex, ezért $\int-\log\zfrac*{f_1}{f_0} f_0\geq -\log\zjel*{\int f_1}=0$.
    \item $-\log$ szigorúan konvex, így egyenlőség csak akkor lehet, ha $-\log \zfrac*{f_1}{f_0}=0$ $\P[0]$ mm., vagyis 
    $f_1=f_0$.
  \end{itemize}    
  \end{frame}

  \begin{frame}{Két apróság}
    \begin{proposition}
      $\Phi$ $N (0,1)$ eloszlásfüggvénye, $(F_n)$ eloszlásfüggvények
      sorozata és  $F_n (t)\to \Phi (t)$ minden $t$-re.  Ekkor
      \begin{enumerate}[<*>]
      \item $\sup\abs*{F_n-\Phi}\to0$ 
      \item $F_n (t_n)\to \Phi (t)$ pontosan akkor ha $t_n\to t$.
      \end{enumerate}
    \end{proposition}
    \begin{itemize}
    \item (1)-et láttuk a  Glivenko--Cantelli
      tétel kapcsán. $F_n,\Phi$ monoton, ha $t_i=\Phi^{-1}(\frac ir)$, $i=1,\dots,r-1$, akkor
      $F_n(t_i)\to\Phi(t_i)=\frac ir$ és %tetszőleges $t$-re 
      $\limsup_{n\to\infty}\sup \abs{F_n-\Phi}
      \leq\lim_{n\to\infty}\max_i \abs{F_n(t_i)-\Phi(t_i)}+\frac1r
      \leq \frac{1}{r}$.
    \item (2) Ha $t_n\to t$ ($t=\pm\infty$ is lehet)
      \begin{displaymath}
        \abs*{F_n (t_n)-\Phi (t)}\leq \abs*{F_n (t_n)-\Phi (t_n)}+\abs*{\Phi(t_n)-\Phi (t)}
        \leq \sup\abs*{F_n-\Phi}+\abs*{\Phi(t_n)-\Phi (t)}\to0
      \end{displaymath}
      
    \item (2) Ha $t_n\not\to t$, akkor létezik $(t'_n)\subset (t_n)$
      részsorozat, aminek létezik limesze $t'$ és az nem $t$ ($t'_n\to\pm\infty$ lehetséges)
      \begin{displaymath}
        F_n (t'_n)\to\Phi (t')\neq\Phi (t)
      \end{displaymath}
      azaz $F_n (t_n)\not\to\Phi (t)$.
    \end{itemize}
    \continue
    Következmény. Ha $t_n=\sup\set{t}{F_n (t)<\alpha}$, akkor $t_n\to\Phi^{-1} (\alpha)$.
  \end{frame}

  \begin{frame}{Erő aszimptotikája}
    \begin{itemize}
    \item Egyszerű hipotézis vizsgálati feladat. $f_1,f_0$ egy mintaelem
      sűrűségfüggvénye. Tegyük fel, hogy $f_1,f_0>0$.
    \item Az $\alpha$ terjedelmű likelihood hányados próba
    \begin{displaymath}
      \phi_n(x)=\I{T_n(x)>c_n}+p_n\I{T_n(x)=c_n},\quad\text{ahol}\quad
      T_n(x)=\prod_{i=1}^n \frac{f_1(x_i)}{f_0(x_i)},\quad
      c_n=e^{-n D(\P[0]\|\P[1])-\sqrt{n}\sigma t_n},\quad t_n\to\Phi^{-1}(\alpha)
    \end{displaymath}
    % \item %Jelölés
    %   \begin{displaymath}
    %     \xi_i=-\log  \frac{f_1(X_i)}{f_0 (X_i)},\quad\text{ekkor}\quad
    %     \E[0]{\xi_i}=\int \log\frac{f_0}{f_1}f_0d\lambda= D(\P[0]\|\P[1])>0            
    %   \end{displaymath}
    %   Tegyük fel, hogy $\E[0]{\xi_i}<\infty$ és $\sigma^2=\D[0]^2{\xi}<\infty$.
    \item $\psi_n$ az erő. A Markov egyenlőtlenségből
      \begin{displaymath}
        1-\psi_n\leq
        \P[1]{\prod_{i=1}^n\frac{f_1 (X_i)}{f_0 (X_i)}\leq c_n}
        =\P[1]{\prod_{i=1}^n\frac{f_0 (X_i)}{f_1 (X_i)}\geq \frac1{c_n}}
        \leq c_n\E[1]{ \prod_{i=1}^n\frac{f_0 (X_i)}{f_1 (X_i)}}=c_n
      \end{displaymath}
      
    \item
      \begin{displaymath}
        1-\psi_n\leq \exp{-n D (\P[0]\|\P[1])+O(\sqrt{n})}
      \end{displaymath}
      Az erő geometria sebességgel tart $1$-hez, ha $n\to\infty$.
    \end{itemize}
  \end{frame}
\end{document}

\end{document}

